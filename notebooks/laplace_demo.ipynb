{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "890645f4-12e3-42b0-902b-0e6e9d6ca79f",
      "metadata": {
        "id": "890645f4-12e3-42b0-902b-0e6e9d6ca79f"
      },
      "source": [
        "# Kronecker-Factored Laplace Approximation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42daa56b-71d6-48da-b3cd-79e07a288341",
      "metadata": {
        "id": "42daa56b-71d6-48da-b3cd-79e07a288341"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "acfa2d37-0637-4abd-8368-c0cd17dc1f34",
      "metadata": {
        "id": "acfa2d37-0637-4abd-8368-c0cd17dc1f34"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from typing import List, Dict, Tuple, Optional, Any\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "from tqdm import tqdm\n",
        "\n",
        "from typing import Any, Dict, List, Optional, Tuple\n",
        "import abc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "YKl1Gsk0r26_",
      "metadata": {
        "cellView": "form",
        "id": "YKl1Gsk0r26_"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "class BaseBayesianEnsemble(abc.ABC):\n",
        "    \"\"\"Базовый класс для всех методов байесовского ансамблирования\"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, **kwargs):\n",
        "        self.model = model\n",
        "        self.is_fitted = False\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def fit(self,\n",
        "            train_loader: torch.utils.data.DataLoader,\n",
        "            val_loader: Optional[torch.utils.data.DataLoader] = None,\n",
        "            **kwargs) -> Dict[str, List[float]]:\n",
        "        \"\"\"Обучение ансамбля\"\"\"\n",
        "        # Надо обсудить параметры и реализацию\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def predict(self,\n",
        "                X: torch.Tensor,\n",
        "                n_samples: int = 100) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"Предсказание с оценкой неопределенности\"\"\"\n",
        "        # Надо обсудить параметры и реализацию\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def sample_models(self, n_models: int = 10) -> List[nn.Module]:\n",
        "        \"\"\"Сэмплирование моделей из апостериорного распределения\"\"\"\n",
        "        # Надо обсудить параметры\n",
        "        pass\n",
        "\n",
        "    def save(self, path: str):\n",
        "        \"\"\"Сохранение обученного ансамбля\"\"\"\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'ensemble_state': self._get_ensemble_state(),\n",
        "            'is_fitted': self.is_fitted\n",
        "        }, path)\n",
        "\n",
        "    def load(self, path: str):\n",
        "        \"\"\"Загрузка обученного ансамбля\"\"\"\n",
        "        checkpoint = torch.load(path)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self._set_ensemble_state(checkpoint['ensemble_state'])\n",
        "        self.is_fitted = checkpoint['is_fitted']\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _get_ensemble_state(self) -> Dict[str, Any]:\n",
        "        \"\"\"Получение внутреннего состояния ансамбля\"\"\"\n",
        "        # Надо обсудить параметры\n",
        "        pass\n",
        "\n",
        "    @abc.abstractmethod\n",
        "    def _set_ensemble_state(self, state: Dict[str, Any]):\n",
        "        \"\"\"Установка внутреннего состояния ансамбля\"\"\"\n",
        "        # Надо обсудить параметры\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3053358-a8cd-4aab-95e6-9977d9833876",
      "metadata": {
        "id": "e3053358-a8cd-4aab-95e6-9977d9833876"
      },
      "source": [
        "## Example model and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "daba35b0-ea6e-4232-bca5-337fc5b6b75e",
      "metadata": {
        "id": "daba35b0-ea6e-4232-bca5-337fc5b6b75e"
      },
      "outputs": [],
      "source": [
        "# Neural Network Models\n",
        "class SimpleNN(nn.Module):\n",
        "    \"\"\"Simple feedforward neural network for MNIST\"\"\"\n",
        "    def __init__(self, input_dim=784, hidden_dims=[1200, 1200], output_dim=10, dropout_rate=0.0):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        layers = []\n",
        "        prev_dim = input_dim\n",
        "\n",
        "        for i, hidden_dim in enumerate(hidden_dims):\n",
        "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
        "            layers.append(nn.ReLU())\n",
        "            if dropout_rate > 0:\n",
        "                layers.append(nn.Dropout(dropout_rate))\n",
        "            prev_dim = hidden_dim\n",
        "\n",
        "        layers.append(nn.Linear(prev_dim, output_dim))\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.network(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2685ff75-0bac-440b-a41c-3a3cddcc4143",
      "metadata": {
        "id": "2685ff75-0bac-440b-a41c-3a3cddcc4143"
      },
      "outputs": [],
      "source": [
        "# Training Function\n",
        "def train_model(model, train_loader, val_loader, num_epochs=50, lr=1e-3, weight_decay=1e-4):\n",
        "    \"\"\"Train a neural network model\"\"\"\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_correct = 0\n",
        "        train_total = 0\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "            _, predicted = output.max(1)\n",
        "            train_total += target.size(0)\n",
        "            train_correct += predicted.eq(target).sum().item()\n",
        "\n",
        "            if batch_idx % 100 == 0:\n",
        "                print(f'Epoch: {epoch}, Batch: {batch_idx}, Loss: {loss.item():.4f}')\n",
        "\n",
        "        train_accuracy = 100. * train_correct / train_total\n",
        "        train_losses.append(train_loss / len(train_loader))\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        val_correct = 0\n",
        "        val_total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in val_loader:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = model(data)\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = output.max(1)\n",
        "                val_total += target.size(0)\n",
        "                val_correct += predicted.eq(target).sum().item()\n",
        "\n",
        "        val_accuracy = 100. * val_correct / val_total\n",
        "        val_losses.append(val_loss / len(val_loader))\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}:')\n",
        "        print(f'  Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_accuracy:.2f}%')\n",
        "        print(f'  Val Loss: {val_losses[-1]:.4f}, Val Acc: {val_accuracy:.2f}%')\n",
        "        print('-' * 50)\n",
        "\n",
        "    return {\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'val_accuracies': val_accuracies\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce452120-6f1e-47cd-af97-97b66c966bf5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce452120-6f1e-47cd-af97-97b66c966bf5",
        "outputId": "b367329f-9939-42a5-8a6f-68e3c5953130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preparing data...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.68MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 114kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.17MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training model...\n",
            "Starting training...\n",
            "Epoch: 0, Batch: 0, Loss: 2.3183\n",
            "Epoch: 0, Batch: 100, Loss: 0.1952\n",
            "Epoch: 0, Batch: 200, Loss: 0.1328\n",
            "Epoch: 0, Batch: 300, Loss: 0.1700\n",
            "Epoch: 0, Batch: 400, Loss: 0.0232\n",
            "Epoch 1/2:\n",
            "  Train Loss: 0.1978, Train Acc: 93.91%\n",
            "  Val Loss: 0.1382, Val Acc: 96.08%\n",
            "--------------------------------------------------\n",
            "Epoch: 1, Batch: 0, Loss: 0.0723\n",
            "Epoch: 1, Batch: 100, Loss: 0.0566\n",
            "Epoch: 1, Batch: 200, Loss: 0.1414\n",
            "Epoch: 1, Batch: 300, Loss: 0.1785\n",
            "Epoch: 1, Batch: 400, Loss: 0.1211\n",
            "Epoch 2/2:\n",
            "  Train Loss: 0.0866, Train Acc: 97.32%\n",
            "  Val Loss: 0.1327, Val Acc: 96.17%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Training pipeline\"\"\"\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Data preparation\n",
        "print(\"Loading and preparing data...\")\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST('../data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('../data', train=False, transform=transform)\n",
        "\n",
        "# Split training data for validation\n",
        "train_size = int(0.9 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_subset, val_subset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=128, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=128, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# Model training\n",
        "print(\"\\nTraining model...\")\n",
        "model = SimpleNN(input_dim=784, hidden_dims=[1200, 1200], output_dim=10)\n",
        "\n",
        "training_history = train_model(\n",
        "    model=model,\n",
        "    train_loader=train_loader,\n",
        "    val_loader=val_loader,\n",
        "    num_epochs=2,\n",
        "    lr=1e-3,\n",
        "    weight_decay=1e-4\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a6e13f-4e5d-4c67-a67c-61b9df2d92ca",
      "metadata": {
        "id": "35a6e13f-4e5d-4c67-a67c-61b9df2d92ca"
      },
      "source": [
        "## KFLA class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "2a9f1907-b913-43b7-9320-d4eb1b294d53",
      "metadata": {
        "id": "2a9f1907-b913-43b7-9320-d4eb1b294d53"
      },
      "outputs": [],
      "source": [
        "class LaplaceApproximation(BaseBayesianEnsemble):\n",
        "    \"\"\"\n",
        "    A scalable Laplace approximation for neural networks based on Kronecker-factored curvature.\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: nn.Module,\n",
        "        pretrained: bool = True,\n",
        "        likelihood: str = 'classification',\n",
        "        verbose: bool = False,\n",
        "    ):\n",
        "        self.model = model\n",
        "        self.is_fitted = False\n",
        "        self.device = next(model.parameters()).device\n",
        "        if likelihood in ['classification', 'regression']:\n",
        "            self.likelihood = likelihood\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported likelihood: {likelihood}\")\n",
        "\n",
        "        self.pretrained = pretrained\n",
        "\n",
        "        # Storage for Kronecker factors\n",
        "        self.kronecker_factors = {}\n",
        "        self.sampling_factors = {}\n",
        "        self.dataset_size = 1\n",
        "\n",
        "        # Hook handles\n",
        "        self.hook_handles = []\n",
        "\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def toggle_verbose(self):\n",
        "        \"\"\"\n",
        "        Turn verbose on or off.\n",
        "        \"\"\"\n",
        "        self.verbose = not self.verbose\n",
        "        print(\"Verbose:\", \"on\" if self.verbose else \"off\")\n",
        "\n",
        "    def fit(self,\n",
        "            train_loader: torch.utils.data.DataLoader,\n",
        "            val_loader: Optional[torch.utils.data.DataLoader] = None,\n",
        "            num_epochs: int = 100,\n",
        "            lr: float = 1e-3,\n",
        "            prior_precision: float = 1.0,\n",
        "            num_samples: int = 1000,\n",
        "           ) -> Dict[str, List[float]]:\n",
        "\n",
        "        history = {}\n",
        "\n",
        "        if not self.pretrained:\n",
        "            if self.verbose:\n",
        "                print('Training model...')\n",
        "            # Сначала обучаем модель MAP оценке\n",
        "            optimizer = torch.optim.Adam(self.model.parameters(), lr=lr)\n",
        "            history['train_loss'] = []\n",
        "\n",
        "            for epoch in range(num_epochs):\n",
        "                self.model.train()\n",
        "                train_loss = 0.0\n",
        "                for batch_X, batch_y in train_loader:\n",
        "                    optimizer.zero_grad()\n",
        "                    output = self.model(batch_X)\n",
        "                    if self.likelihood == 'classification':\n",
        "                        loss = F.cross_entropy(output, batch_y)\n",
        "                    else:\n",
        "                        loss = F.mse_loss(output, batch_y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    train_loss += loss.item()\n",
        "\n",
        "                total_loss = train_loss / len(train_loader)\n",
        "                history['train_loss'].append(total_loss)\n",
        "\n",
        "                if self.verbose:\n",
        "                    print(f'Epoch {epoch}: training loss = {total_loss:.4f}')\n",
        "\n",
        "            self.pretrained = True\n",
        "\n",
        "        self.compute_posterior(train_loader, prior_precision, num_samples)\n",
        "\n",
        "        return history\n",
        "\n",
        "    def compute_posterior(self,\n",
        "                         train_loader: DataLoader,\n",
        "                         prior_precision: float = 0.0,\n",
        "                         num_samples: int = 1000) -> None:\n",
        "        \"\"\"\n",
        "        Compute the Kronecker-factored Laplace approximation.\n",
        "        \"\"\"\n",
        "        self.prior_precision = prior_precision\n",
        "        self.dataset_size = len(train_loader.dataset)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"Registering hooks...\")\n",
        "        self._register_hooks()\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"Estimating Kronecker factors...\")\n",
        "        self._estimate_kronecker_factors(train_loader, num_samples)\n",
        "\n",
        "        if self.verbose:\n",
        "            print(\"Removing hooks...\")\n",
        "        self._remove_hooks()\n",
        "\n",
        "        print(\"Posterior computation completed!\")\n",
        "\n",
        "    def _register_hooks(self) -> None:\n",
        "        \"\"\"Register forward hooks to capture activations and pre-activation Hessians.\"\"\"\n",
        "        self.activations = {}\n",
        "        self.pre_activation_hessians = {}\n",
        "\n",
        "        def make_forward_hook(layer_name):\n",
        "            def forward_hook(module, input, output):\n",
        "                if isinstance(input, tuple):\n",
        "                    input = input[0]\n",
        "                # Store input activations for Q factor\n",
        "                self.activations[layer_name] = input.detach().clone()\n",
        "            return forward_hook\n",
        "\n",
        "        # Register hooks for linear layers\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                forward_handle = module.register_forward_hook(make_forward_hook(name))\n",
        "                self.hook_handles.append(forward_handle)\n",
        "\n",
        "    def _remove_hooks(self) -> None:\n",
        "        \"\"\"Remove all registered hooks.\"\"\"\n",
        "        for handle in self.hook_handles:\n",
        "            handle.remove()\n",
        "        self.hook_handles.clear()\n",
        "\n",
        "    def _compute_pre_activation_hessian(self, output, target):\n",
        "        \"\"\"\n",
        "        Compute the Hessian with respect to the final layer pre-activations.\n",
        "        This depends on the likelihood function.\n",
        "        \"\"\"\n",
        "        batch_size = output.shape[0]\n",
        "\n",
        "        if self.likelihood == 'classification':\n",
        "            # For cross-entropy loss with softmax, the Hessian is:\n",
        "            # H = diag(p) - pp^T, where p is the softmax probabilities\n",
        "            probs = F.softmax(output, dim=1)\n",
        "            eye = torch.eye(probs.size(1), device=self.device).unsqueeze(0)  # (1, C, C)\n",
        "            probs_outer = torch.einsum('bi,bj->bij', probs, probs)  # (B, C, C)\n",
        "            hessian = probs_outer - eye  # This is actually -H, but we'll account for sign later\n",
        "            return -hessian  # Return the negative Hessian of NLL\n",
        "\n",
        "        else: # self.likelihood == 'regression':\n",
        "            # For MSE loss, the Hessian is identity\n",
        "            output_dim = output.shape[1]\n",
        "            hessian = torch.eye(output_dim, device=self.device).unsqueeze(0).repeat(batch_size, 1, 1)\n",
        "            return hessian\n",
        "\n",
        "\n",
        "    def _backward_hessian(self, hessian_final):\n",
        "        \"\"\"\n",
        "        Correct recursive backpropagation of pre-activation Hessian.\n",
        "        Uses weights of the NEXT layer to compute Hessian for the CURRENT layer.\n",
        "        \"\"\"\n",
        "        hessians = {}\n",
        "\n",
        "        # Get all linear layers in forward order\n",
        "        linear_layers = []\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, nn.Linear):\n",
        "                linear_layers.append((name, module))\n",
        "\n",
        "        # Initialize with the final layer Hessian\n",
        "        if hessian_final.dim() == 3:\n",
        "            current_hessian = hessian_final.mean(0)  # Average over batch\n",
        "        else:\n",
        "            current_hessian = hessian_final\n",
        "\n",
        "        final_layer_name, final_layer = linear_layers[-1]\n",
        "        hessians[final_layer_name] = current_hessian\n",
        "\n",
        "        # Backpropagate through layers in REVERSE order (from output to input)\n",
        "        for i in range(len(linear_layers) - 2, -1, -1):  # Start from second-to-last layer\n",
        "            current_layer_name, current_layer = linear_layers[i]\n",
        "            next_layer_name, next_layer = linear_layers[i + 1]\n",
        "\n",
        "            # The recursive formula: H_λ = W_{λ+1}^T @ H_{λ+1} @ W_{λ+1} + D_λ\n",
        "            # For piecewise linear activations (ReLU), D_λ ≈ 0\n",
        "            W_next = next_layer.weight  # Shape: (out_dim_{λ+1}, in_dim_{λ+1})\n",
        "\n",
        "            # H_current = W_next^T @ H_next @ W_next\n",
        "            H_current = W_next.T @ current_hessian @ W_next\n",
        "\n",
        "            # Store the Hessian for this layer\n",
        "            hessians[current_layer_name] = H_current\n",
        "\n",
        "            # Update for next iteration\n",
        "            current_hessian = H_current\n",
        "\n",
        "        return hessians\n",
        "\n",
        "    def _estimate_kronecker_factors(self, train_loader: DataLoader, num_samples: int) -> None:\n",
        "        \"\"\"\n",
        "        Estimate Kronecker factors using proper Hessian computation.\n",
        "        \"\"\"\n",
        "        self.model.eval()  # We want deterministic behavior for curvature estimation\n",
        "\n",
        "        accumulators = {}\n",
        "        sample_count = 0\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"Processing up to {num_samples} samples...\")\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            if sample_count >= num_samples:\n",
        "                break\n",
        "\n",
        "            data, target = data.to(self.device), target.to(self.device)\n",
        "            batch_size = data.shape[0]\n",
        "\n",
        "            # Forward pass\n",
        "            output = self.model(data)\n",
        "\n",
        "            # Compute pre-activation Hessian for the final layer\n",
        "            H_final = self._compute_pre_activation_hessian(output, target)\n",
        "\n",
        "            # Backpropagate Hessian through all layers\n",
        "            layer_hessians = self._backward_hessian(H_final)\n",
        "\n",
        "            # Process each layer\n",
        "            with torch.no_grad():\n",
        "                for name, module in self.model.named_modules():\n",
        "                    if isinstance(module, nn.Linear) and name in self.activations and name in layer_hessians:\n",
        "                        a = self.activations[name]  # input activations (B, in_dim)\n",
        "                        H = layer_hessians[name]    # pre-activation Hessian (out_dim, out_dim)\n",
        "\n",
        "                        if name not in accumulators:\n",
        "                            in_dim = a.shape[1]\n",
        "                            out_dim = H.shape[0] if H.dim() == 2 else H.shape[1]\n",
        "\n",
        "                            accumulators[name] = {\n",
        "                                'Q_sum': torch.zeros(in_dim, in_dim, device=self.device),\n",
        "                                'H_sum': torch.zeros(out_dim, out_dim, device=self.device),\n",
        "                                'count': 0,\n",
        "                                'in_dim': in_dim,\n",
        "                                'out_dim': out_dim\n",
        "                            }\n",
        "\n",
        "                        # Compute Q factor: covariance of input activations\n",
        "                        batch_Q = torch.einsum('bi,bj->ij', a, a) / batch_size\n",
        "\n",
        "                        # H factor is already computed from backpropagation\n",
        "                        # Average if we have multiple samples\n",
        "                        if H.dim() == 3:  # batch of Hessians\n",
        "                            batch_H = H.mean(0)\n",
        "                        else:\n",
        "                            batch_H = H\n",
        "\n",
        "                        accumulators[name]['Q_sum'] += batch_Q * batch_size\n",
        "                        accumulators[name]['H_sum'] += batch_H * batch_size\n",
        "                        accumulators[name]['count'] += batch_size\n",
        "\n",
        "                sample_count += batch_size\n",
        "                if sample_count % 1000 == 0 and self.verbose:\n",
        "                    print(f\"Processed {sample_count} samples...\")\n",
        "\n",
        "        # Compute final factors with proper regularization\n",
        "        if self.verbose:\n",
        "            print(\"Computing final Kronecker factors...\")\n",
        "        with torch.no_grad():\n",
        "            for name, acc in accumulators.items():\n",
        "                if acc['count'] == 0:\n",
        "                    continue\n",
        "\n",
        "                # Expected Kronecker factors (Equation 7 in the paper)\n",
        "                Q = acc['Q_sum'] / acc['count']  # E[Q_λ]\n",
        "                H = acc['H_sum'] / acc['count']  # E[H_λ]\n",
        "\n",
        "                # Add prior precision and scale by dataset size (Equation 9)\n",
        "                N = self.dataset_size\n",
        "                tau = self.prior_precision\n",
        "\n",
        "                Q_reg = np.sqrt(N) * Q + np.sqrt(tau) * torch.eye(acc['in_dim'], device=self.device)\n",
        "                H_reg = np.sqrt(N) * H + np.sqrt(tau) * torch.eye(acc['out_dim'], device=self.device)\n",
        "\n",
        "                # Store the precision matrices for sampling\n",
        "                self.kronecker_factors[name] = {\n",
        "                    'Q': Q_reg,  # Precision for rows\n",
        "                    'H': H_reg,  # Precision for columns\n",
        "                }\n",
        "\n",
        "                if self.verbose:\n",
        "                    print(f\"Layer {name}:\\nQ shape {Q_reg.shape}, H shape {H_reg.shape}\")\n",
        "                    Q_norm = torch.norm(Q_reg).item()\n",
        "                    H_norm = torch.norm(H_reg).item()\n",
        "                    print(f\"  Q norm: {Q_norm:.6f}, H norm: {H_norm:.6f}\")\n",
        "                    cond_Q = torch.linalg.cond(Q_reg)\n",
        "                    cond_H = torch.linalg.cond(H_reg)\n",
        "                    print(f\"cond(Q)={cond_Q:.2e}, cond(H)={cond_H:.2e}\")\n",
        "\n",
        "                # Convert to covariance matrices for sampling\n",
        "                U = torch.linalg.inv(Q_reg)  # Row covariance\n",
        "                V = torch.linalg.inv(H_reg)  # Column covariance\n",
        "\n",
        "                # Matrix sqrt for sampling\n",
        "                L_U = self._matrix_sqrt(U)\n",
        "                L_V = self._matrix_sqrt(V)\n",
        "\n",
        "                self.sampling_factors[name] = {\n",
        "                    'L_U': L_U,\n",
        "                    'L_V': L_V,\n",
        "                    'weight_shape': (acc['out_dim'], acc['in_dim'])\n",
        "                }\n",
        "\n",
        "    def _matrix_sqrt(self, A: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Compute matrix square root using eigen decomposition.\"\"\"\n",
        "        # Eigen decomposition for symmetric matrices\n",
        "        L, V = torch.linalg.eigh(A)\n",
        "        return V @ torch.diag(torch.sqrt(L)) @ V.T\n",
        "\n",
        "    def sample_models(self, n_models: int = 10, temperature: float = 1.0) -> List[nn.Module]:\n",
        "        \"\"\"\n",
        "        Sample weight matrices from the matrix normal posterior.\n",
        "        Returns a list of dictionaries, where each dictionary contains\n",
        "        the complete set of weights for one sampled model.\n",
        "\n",
        "        Args:\n",
        "            num_samples: Number of model samples to generate\n",
        "\n",
        "        Returns:\n",
        "            List of dictionaries, where each dict has layer names as keys\n",
        "            and sampled weight tensors as values\n",
        "        \"\"\"\n",
        "        samples = []\n",
        "\n",
        "        for i in range(n_models):\n",
        "            weight_sample = {}\n",
        "\n",
        "            for name, factors in self.sampling_factors.items():\n",
        "                module = dict(self.model.named_modules())[name]\n",
        "                M = module.weight.data  # MAP estimate\n",
        "\n",
        "                L_V = factors['L_V']  # Row precision (in_dim, in_dim)\n",
        "                L_U = factors['L_U']  # Column precision (out_dim, out_dim)\n",
        "                weight_shape = factors['weight_shape']\n",
        "\n",
        "                # Generate single sample for this layer\n",
        "                Z = torch.randn(weight_shape, device=self.device)\n",
        "                W_sample = M + temperature * L_V @ Z @ L_U.T\n",
        "\n",
        "                # Store in the model sample dictionary\n",
        "                weight_sample[f\"{name}.weight\"] = W_sample.cpu()\n",
        "\n",
        "            # Also include bias terms if they exist\n",
        "            for name, module in self.model.named_modules():\n",
        "                if isinstance(module, nn.Linear) and module.bias is not None:\n",
        "                    # For bias, we can use a simple diagonal approximation\n",
        "                    # or sample from the appropriate marginal distribution\n",
        "                    if name in self.kronecker_factors:\n",
        "                        # The bias is typically part of the same layer's distribution\n",
        "                        # but for simplicity, we'll use the MAP estimate for bias\n",
        "                        weight_sample[f\"{name}.bias\"] = module.bias.data.clone()\n",
        "\n",
        "            model_sample = copy.deepcopy(self.model)\n",
        "            model_sample.load_state_dict(weight_sample)\n",
        "\n",
        "            samples.append(model_sample)\n",
        "\n",
        "        return samples\n",
        "\n",
        "    def predict(self,\n",
        "                X: torch.Tensor,\n",
        "                n_samples: int = 100,\n",
        "                temperature: float = 1.0) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Compute predictive distribution using sampled weights.\n",
        "        \"\"\"\n",
        "        predictions = []\n",
        "\n",
        "        for _ in range(n_samples):\n",
        "            sampled_model = self.sample_models(n_models=1, temperature=temperature)[0]\n",
        "            sampled_model.to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                output = sampled_model(X)\n",
        "                predictions.append(output)\n",
        "\n",
        "            sampled_model.cpu()\n",
        "\n",
        "        predictions = torch.stack(predictions)\n",
        "\n",
        "        if self.likelihood == 'classification':\n",
        "            probs = F.softmax(predictions, dim=-1)\n",
        "            mean_probs = probs.mean(dim=0)\n",
        "            uncertainty = -(mean_probs * torch.log(mean_probs + 1e-8)).sum(dim=-1)\n",
        "            return mean_probs, uncertainty\n",
        "        else:\n",
        "            mean = predictions.mean(dim=0)\n",
        "            variance = predictions.var(dim=0)\n",
        "            return mean, variance\n",
        "\n",
        "    def _get_ensemble_state(self) -> Dict[str, Any]:\n",
        "        \"\"\"Получение внутреннего состояния ансамбля\"\"\"\n",
        "        return {\n",
        "            'model': self.model,\n",
        "            'is_fitted': self.is_fitted,\n",
        "            'device': self.device,\n",
        "            'likelihood': self.likelihood,\n",
        "            'pretrained': self.pretrained,\n",
        "            'kronecker_factors': self.kronecker_factors,\n",
        "            'sampling_factors': self.sampling_factors,\n",
        "            'dataset_size': self.dataset_size,\n",
        "            'hook_handles': self.hook_handles,\n",
        "            'verbose': self.verbose,\n",
        "        }\n",
        "\n",
        "    def _set_ensemble_state(self, state: Dict[str, Any]):\n",
        "        \"\"\"Установка внутреннего состояния ансамбля\"\"\"\n",
        "        if state['likelihood'] in ['classification', 'regression']:\n",
        "            self.likelihood = state['']\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported likelihood: {state['']}\")\n",
        "\n",
        "        self.model = state['model']\n",
        "        self.is_fitted = state['is_fitted']\n",
        "        self.device = state['device']\n",
        "        self.pretrained = state['pretrained']\n",
        "        self.kronecker_factors = state['kronecker_factors']\n",
        "        self.sampling_factors = state['sampling_factors']\n",
        "        self.dataset_size = state['dataset_size']\n",
        "        self.hook_handles = state['hook_handles']\n",
        "        self.verbose = state['verbose']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "37fce12b-719c-4a2c-8d7e-f2beca125902",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37fce12b-719c-4a2c-8d7e-f2beca125902",
        "outputId": "ee9dffcd-6c99-48d6-f6cd-7b5441dcc47f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating KFLA...\n",
            "Computing posterior...\n",
            "Registering hooks...\n",
            "Estimating Kronecker factors...\n",
            "Processing up to 60000 samples...\n",
            "Processed 16000 samples...\n",
            "Processed 32000 samples...\n",
            "Processed 48000 samples...\n",
            "Processed 54000 samples...\n",
            "Computing final Kronecker factors...\n",
            "Layer network.0:\n",
            "Q shape torch.Size([784, 784]), H shape torch.Size([1200, 1200])\n",
            "  Q norm: 62008.597656, H norm: 10311.433594\n",
            "cond(Q)=5.81e+04, cond(H)=6.06e+03\n",
            "Layer network.2:\n",
            "Q shape torch.Size([1200, 1200]), H shape torch.Size([1200, 1200])\n",
            "  Q norm: 29033.296875, H norm: 534.191406\n",
            "cond(Q)=2.29e+04, cond(H)=2.50e+02\n",
            "Layer network.4:\n",
            "Q shape torch.Size([1200, 1200]), H shape torch.Size([10, 10])\n",
            "  Q norm: 94298.226562, H norm: 667.978699\n",
            "cond(Q)=7.99e+04, cond(H)=1.04e+00\n",
            "Removing hooks...\n",
            "Posterior computation completed!\n"
          ]
        }
      ],
      "source": [
        "# Let's test with extremely conservative settings\n",
        "print(\"Creating KFLA...\")\n",
        "\n",
        "# Make sure the model is on the correct device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Create the Laplace approximation\n",
        "laplace = LaplaceApproximation(model, likelihood='classification', verbose=True)\n",
        "\n",
        "# Compute the posterior\n",
        "print(\"Computing posterior...\")\n",
        "laplace.compute_posterior(\n",
        "    train_loader=train_loader,\n",
        "    prior_precision=1.0,\n",
        "    num_samples=len(train_dataset)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cadd5204-1179-46ab-b8ae-f6c849f26a34",
      "metadata": {
        "id": "cadd5204-1179-46ab-b8ae-f6c849f26a34"
      },
      "source": [
        "## KFLA evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "345f76fb-da35-40ab-b436-6373ec05ebc0",
      "metadata": {
        "id": "345f76fb-da35-40ab-b436-6373ec05ebc0"
      },
      "outputs": [],
      "source": [
        "# Evaluation functions\n",
        "def evaluate_laplace_model(laplace, test_loader, num_samples=10, temperature=1.0):\n",
        "    \"\"\"Evaluate the model with Laplace approximation\"\"\"\n",
        "    laplace.model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    uncertainties = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            mean_probs, uncertainty = laplace.predict(\n",
        "                data, n_samples=num_samples, temperature=temperature\n",
        "            )\n",
        "\n",
        "            _, predicted = mean_probs.max(1)\n",
        "\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "            uncertainties.extend(uncertainty.cpu().numpy())\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_uncertainty = np.mean(uncertainties)\n",
        "\n",
        "    return accuracy, avg_uncertainty, uncertainties\n",
        "\n",
        "def evaluate_standard_model(model, test_loader):\n",
        "    \"\"\"Evaluate the standard model\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            _, predicted = output.max(1)\n",
        "            total += target.size(0)\n",
        "            correct += predicted.eq(target).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a8850d6b-e61b-4f20-b37b-f7369f8555cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8850d6b-e61b-4f20-b37b-f7369f8555cf",
        "outputId": "844f3c54-b996-497d-92b0-cb4a6744555e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating standard model...\n",
            "Standard Model Accuracy: 95.91%\n"
          ]
        }
      ],
      "source": [
        "# Test standard model first\n",
        "print(\"\\nEvaluating standard model...\")\n",
        "standard_accuracy = evaluate_standard_model(model, test_loader)\n",
        "print(f\"Standard Model Accuracy: {standard_accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "86215ff7-64a2-4dea-9597-768ad177531f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86215ff7-64a2-4dea-9597-768ad177531f",
        "outputId": "a9420dba-b29b-4e0e-cc5d-6a2cc2fa35b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:12<00:00,  6.35it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 samples, T = 1.0: Accuracy = 68.74%, Uncertainty = 1.2498\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "accuracy, uncertainty, _ = evaluate_laplace_model(\n",
        "    laplace, test_loader, num_samples=10, temperature=1.0\n",
        ")\n",
        "print(f\"10 samples, T = 1.0: Accuracy = {accuracy:.2f}%, Uncertainty = {uncertainty:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ad0209-729b-492c-ad0b-74a3294da13a",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7ad0209-729b-492c-ad0b-74a3294da13a",
        "outputId": "8f89f5e2-1e7b-425c-a0d8-e2dc92130586"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10 samples, T = 1.0: Accuracy = 68.41%, Uncertainty = 1.2487\n",
            "20 samples, T = 1.0: Accuracy = 73.72%, Uncertainty = 1.3669\n",
            "50 samples, T = 1.0: Accuracy = 76.20%, Uncertainty = 1.4506\n",
            "100 samples, T = 1.0: Accuracy = 77.43%, Uncertainty = 1.4796\n",
            "200 samples, T = 1.0: Accuracy = 77.97%, Uncertainty = 1.4932\n"
          ]
        }
      ],
      "source": [
        "for n_samples in [10, 20, 50, 100, 200]:\n",
        "    accuracy, uncertainty, _ = evaluate_laplace_model(\n",
        "        laplace, test_loader, num_samples=n_samples, temperature=1.0\n",
        "    )\n",
        "    print(f\"{n_samples} samples, T = 1.0: Accuracy = {accuracy:.2f}%, Uncertainty = {uncertainty:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "a9196d03-49fe-465d-bfb3-698edf6fa150",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9196d03-49fe-465d-bfb3-698edf6fa150",
        "outputId": "4b7d1df6-7fb5-4697-aa9f-8a8722a439eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing Laplace with different temperatures:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:12<00:00,  6.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature 0.001: Accuracy = 95.91%, Uncertainty = 0.1048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:12<00:00,  6.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature 0.01: Accuracy = 95.92%, Uncertainty = 0.1048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:12<00:00,  6.56it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature 0.1: Accuracy = 95.90%, Uncertainty = 0.1059\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:13<00:00,  5.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature 1: Accuracy = 69.61%, Uncertainty = 1.2507\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 79/79 [00:12<00:00,  6.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temperature 10: Accuracy = 10.36%, Uncertainty = 1.7648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Test Laplace with very conservative temperatures\n",
        "print(\"\\nTesting Laplace with different temperatures:\")\n",
        "temperatures = [0.001, 0.01, 0.1, 1, 10]\n",
        "\n",
        "for temp in temperatures:\n",
        "    accuracy, uncertainty, _ = evaluate_laplace_model(\n",
        "        laplace, test_loader, num_samples=10, temperature=temp\n",
        "    )\n",
        "    print(f\"Temperature {temp}: Accuracy = {accuracy:.2f}%, Uncertainty = {uncertainty:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "6423ae8a-267b-4168-b370-e9ff6d4cbc5e",
      "metadata": {
        "id": "6423ae8a-267b-4168-b370-e9ff6d4cbc5e"
      },
      "outputs": [],
      "source": [
        "# Let's also look at uncertainty for correct vs incorrect predictions\n",
        "def analyze_uncertainty_by_accuracy(laplace, test_loader, num_samples=10):\n",
        "    \"\"\"Analyze uncertainty for correct vs incorrect predictions\"\"\"\n",
        "    laplace.model.eval()\n",
        "    correct_uncertainties = []\n",
        "    incorrect_uncertainties = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(test_loader):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # Get predictive distribution using Laplace approximation\n",
        "            mean_probs, uncertainty = laplace.predict(data, n_samples=num_samples)\n",
        "\n",
        "            # Get predictions\n",
        "            _, predicted = mean_probs.max(1)\n",
        "\n",
        "            # Separate uncertainties for correct and incorrect predictions\n",
        "            correct_mask = predicted.eq(target)\n",
        "            incorrect_mask = ~correct_mask\n",
        "\n",
        "            if correct_mask.any():\n",
        "                correct_uncertainties.extend(uncertainty[correct_mask].cpu().numpy())\n",
        "            if incorrect_mask.any():\n",
        "                incorrect_uncertainties.extend(uncertainty[incorrect_mask].cpu().numpy())\n",
        "\n",
        "    return correct_uncertainties, incorrect_uncertainties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "19e6ef8b-9451-4105-af52-0e1a4112ccc0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19e6ef8b-9451-4105-af52-0e1a4112ccc0",
        "outputId": "9ebba80e-3fa8-4d8f-9243-3e344513f197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Uncertainty Analysis:\n",
            "Average uncertainty for correct predictions: 1.1289\n",
            "Average uncertainty for incorrect predictions: 1.5216\n",
            "Number of correct predictions: 6891\n",
            "Number of incorrect predictions: 3109\n"
          ]
        }
      ],
      "source": [
        "correct_unc, incorrect_unc = analyze_uncertainty_by_accuracy(laplace, test_loader)\n",
        "\n",
        "print(f\"\\nUncertainty Analysis:\")\n",
        "print(f\"Average uncertainty for correct predictions: {np.mean(correct_unc):.4f}\")\n",
        "print(f\"Average uncertainty for incorrect predictions: {np.mean(incorrect_unc):.4f}\")\n",
        "print(f\"Number of correct predictions: {len(correct_unc)}\")\n",
        "print(f\"Number of incorrect predictions: {len(incorrect_unc)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "67cd6656-ea0e-4932-b14b-f76e303f3290",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67cd6656-ea0e-4932-b14b-f76e303f3290",
        "outputId": "9e1b7400-ac69-48dd-a1ce-d3fee24025e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Testing on a single batch...\n",
            "Predictions for first 10 test samples:\n",
            "  Sample 1: True=7, Pred=7, Uncertainty=1.2757, Correct=True\n",
            "  Sample 2: True=2, Pred=2, Uncertainty=1.3885, Correct=True\n",
            "  Sample 3: True=1, Pred=1, Uncertainty=1.5347, Correct=True\n",
            "  Sample 4: True=0, Pred=2, Uncertainty=1.5881, Correct=False\n",
            "  Sample 5: True=4, Pred=9, Uncertainty=1.3691, Correct=False\n",
            "  Sample 6: True=1, Pred=1, Uncertainty=0.6458, Correct=True\n",
            "  Sample 7: True=4, Pred=5, Uncertainty=1.5984, Correct=False\n",
            "  Sample 8: True=9, Pred=9, Uncertainty=1.6587, Correct=True\n",
            "  Sample 9: True=5, Pred=5, Uncertainty=1.5540, Correct=True\n",
            "  Sample 10: True=9, Pred=9, Uncertainty=1.1116, Correct=True\n"
          ]
        }
      ],
      "source": [
        "# Example of getting predictions with uncertainty for a single batch\n",
        "print(\"\\nTesting on a single batch...\")\n",
        "data_iter = iter(test_loader)\n",
        "test_data, test_target = next(data_iter)\n",
        "test_data, test_target = test_data.to(device), test_target.to(device)\n",
        "\n",
        "mean_probs, uncertainty = laplace.predict(test_data, n_samples=10)\n",
        "_, predicted = mean_probs.max(1)\n",
        "\n",
        "print(f\"Predictions for first 10 test samples:\")\n",
        "for i in range(min(10, len(test_data))):\n",
        "    print(f\"  Sample {i+1}: True={test_target[i].item()}, Pred={predicted[i].item()}, \"\n",
        "          f\"Uncertainty={uncertainty[i].item():.4f}, \"\n",
        "          f\"Correct={predicted[i].eq(test_target[i]).item()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "gSGfs4sK2Fth",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSGfs4sK2Fth",
        "outputId": "beb123f3-c14f-43e4-80e3-4485ee895237"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleNN(\n",
              "  (network): Sequential(\n",
              "    (0): Linear(in_features=784, out_features=1200, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Linear(in_features=1200, out_features=1200, bias=True)\n",
              "    (3): ReLU()\n",
              "    (4): Linear(in_features=1200, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_samples = laplace.sample_models(n_models=10)\n",
        "model_samples[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "e3053358-a8cd-4aab-95e6-9977d9833876"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
