{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50e23394",
   "metadata": {},
   "source": [
    "# Probabilistic Backpropagation Demo on Housing Benchmark\n",
    "This is a demo of the Probabilistic Backpropogation algorithm implemented in the `ProbabilisticBackpropagation` class in Bensemble. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dbb7b2-18a6-4a44-a595-d73946d1ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "497e8cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cuda with seed 7\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sys.path.append(str(pathlib.Path(\"../..\").resolve()))\n",
    "from bensemble.methods.probabilistic_backpropagation import ProbabilisticBackpropagation\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 7\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(f\"Running on {DEVICE} with seed {SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9158d8-859f-4f40-89e2-dc64e1e7e04c",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27322600-d9f8-4c30-b813-90c8a5ee5841",
   "metadata": {},
   "source": [
    "We will test the `ProbabilisticBackpropagation` implementation using the Boston housing-style dataset from our [benchmark demo](https://github.com/intsystems/bensemble/blob/master/notebooks/benchmark.ipynb) `benchmark.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8473ca31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n",
      "Train size: 404, Test size: 102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\jommm\\AppData\\Local\\Temp\\ipykernel_20760\\3803673090.py:10: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  df = pd.read_csv(DATA_PATH, sep='\\s+', header=None, names=COLUMN_NAMES)\n"
     ]
    }
   ],
   "source": [
    "DATA_CANDIDATES = [\n",
    "    pathlib.Path(\"data/housing.data\"),\n",
    "    pathlib.Path(\"../data/housing.data\"),\n",
    "    pathlib.Path(\"../../benchmark/data/housing.data\"),\n",
    "]\n",
    "DATA_PATH = next((p for p in DATA_CANDIDATES if p.exists()), None)\n",
    "if DATA_PATH is None:\n",
    "    raise FileNotFoundError(\"housing.data not found in known locations\")\n",
    "COLUMN_NAMES = [\n",
    "    \"CRIM\",\n",
    "    \"ZN\",\n",
    "    \"INDUS\",\n",
    "    \"CHAS\",\n",
    "    \"NOX\",\n",
    "    \"RM\",\n",
    "    \"AGE\",\n",
    "    \"DIS\",\n",
    "    \"RAD\",\n",
    "    \"TAX\",\n",
    "    \"PTRATIO\",\n",
    "    \"B\",\n",
    "    \"LSTAT\",\n",
    "    \"MEDV\",\n",
    "]\n",
    "\n",
    "df = pd.read_csv(DATA_PATH, sep=\"\\s+\", header=None, names=COLUMN_NAMES)\n",
    "print(df.shape)\n",
    "\n",
    "TARGET_COL = \"MEDV\"\n",
    "TEST_SIZE = 0.2\n",
    "X = df.drop(columns=[TARGET_COL]).values.astype(np.float32)\n",
    "y = df[TARGET_COL].values.astype(np.float32).reshape(-1, 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, random_state=SEED\n",
    ")\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "y_scaler = StandardScaler()\n",
    "X_train_scaled = x_scaler.fit_transform(X_train).astype(np.float32)\n",
    "X_test_scaled = x_scaler.transform(X_test).astype(np.float32)\n",
    "y_train_scaled = y_scaler.fit_transform(y_train).astype(np.float32)\n",
    "y_test_scaled = y_scaler.transform(y_test).astype(np.float32)\n",
    "\n",
    "train_tensor_x = torch.from_numpy(X_train_scaled)\n",
    "train_tensor_y = torch.from_numpy(y_train_scaled)\n",
    "test_tensor_x = torch.from_numpy(X_test_scaled)\n",
    "test_tensor_y = torch.from_numpy(y_test_scaled)\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(train_tensor_x, train_tensor_y), batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(test_tensor_x, test_tensor_y),\n",
    "    batch_size=len(test_tensor_x),\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "Y_SCALE = float(y_scaler.scale_[0])\n",
    "Y_MEAN = float(y_scaler.mean_[0])\n",
    "y_test_true = y_test.reshape(-1)\n",
    "print(f\"Train size: {len(train_tensor_x)}, Test size: {len(test_tensor_x)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "649d871a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3682809469879644, 0.36836619896285056, 0.36872475628900075]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pbp = ProbabilisticBackpropagation(\n",
    "    layer_sizes=[train_tensor_x.shape[1], 64, 1], device=DEVICE\n",
    ")\n",
    "history = pbp.fit(train_loader, num_epochs=80, step_clip=2.0, prior_refresh=1)\n",
    "history[\"train_rmse\"][-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fff3071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE (original scale): 5.5321\n",
      "Test NLPD (original scale): 3.4671\n",
      "Estimated noise variance (scaled): 0.1332\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    # Predict on the full test set (scaled)\n",
    "    test_batch = next(iter(test_loader))[0].to(DEVICE, dtype=torch.float64)\n",
    "    mean_scaled, samples_scaled = pbp.predict(test_batch, n_samples=200)\n",
    "    _, var_scaled = pbp._predictive_mean_var(test_batch)\n",
    "\n",
    "# Convert predictions back to original scale\n",
    "mean_np = y_scaler.inverse_transform(mean_scaled.cpu().numpy()).reshape(-1)\n",
    "var_np = var_scaled.cpu().numpy().reshape(-1) * (Y_SCALE**2)\n",
    "samples_np = y_scaler.inverse_transform(\n",
    "    samples_scaled.cpu().numpy().reshape(samples_scaled.shape[0], -1)\n",
    ")\n",
    "rmse = float(np.sqrt(np.mean((mean_np - y_test_true) ** 2)))\n",
    "nlpd = float(\n",
    "    0.5\n",
    "    * np.mean(np.log(2 * math.pi * var_np) + ((y_test_true - mean_np) ** 2) / var_np)\n",
    ")\n",
    "assert rmse < 6.0, f\"RMSE too high: {rmse}\"\n",
    "assert float(np.var(samples_np)) > 0.0\n",
    "print(f\"Test RMSE (original scale): {rmse:.4f}\")\n",
    "print(f\"Test NLPD (original scale): {nlpd:.4f}\")\n",
    "print(f\"Estimated noise variance (scaled): {pbp.noise_variance().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ba99f",
   "metadata": {},
   "source": [
    "## Sampling concrete models\n",
    "We can sample deterministic networks from the posterior approximation to inspect epistemic uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02952542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled-model RMSE: 5.5416\n",
      "Epistemic variance (mean over test): 0.0742\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    test_x = test_tensor_x.to(DEVICE, dtype=torch.float64)\n",
    "    sampled_models = pbp.sample_models(n_models=20)\n",
    "    sampled_preds = []\n",
    "    for sm in sampled_models:\n",
    "        sm = sm.to(DEVICE)\n",
    "        outputs = sm(test_x).cpu().numpy()  # scaled space\n",
    "        sampled_preds.append(outputs)\n",
    "\n",
    "# Back to original scale for metrics\n",
    "sampled_preds = np.stack(sampled_preds, axis=0)  # (S, N, 1)\n",
    "sampled_preds_orig = np.stack(\n",
    "    [y_scaler.inverse_transform(p.reshape(-1, 1)).reshape(-1) for p in sampled_preds],\n",
    "    axis=0,\n",
    ")\n",
    "mean_pred = sampled_preds_orig.mean(axis=0)\n",
    "epistemic_var = sampled_preds_orig.var(axis=0)\n",
    "rmse_samples = float(np.sqrt(np.mean((mean_pred - y_test_true) ** 2)))\n",
    "print(f\"Sampled-model RMSE: {rmse_samples:.4f}\")\n",
    "print(f\"Epistemic variance (mean over test): {float(epistemic_var.mean()):.4f}\")\n",
    "assert float(epistemic_var.mean()) > 0.0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "windows_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
